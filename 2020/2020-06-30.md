## June 30th 2020

### Guillaume
* Cutting in small pieces some PR related to weighted percentile:
  * implementation of weighted percentile https://github.com/scikit-learn/scikit-learn/pull/17768
  * exposed interpolation parameter to DummyRegressor https://github.com/scikit-learn/scikit-learn/pull/17775
  * solving the consistency in GradienBoostingRegressor
* Check the issue with ROC auc score https://github.com/scikit-learn/scikit-learn/pull/17704
* Go back to post-tune decision function estimator https://github.com/scikit-learn/scikit-learn/pull/16525
* Will work on the MOOC on Wednesday (+meeting sync with Loïc and Gaël)

### Chiara:
* MiniBatchNMF (https://github.com/scikit-learn/scikit-learn/pull/16948): code simplification
* Iterable values in dictVectorizer (https://github.com/scikit-learn/scikit-learn/pull/17367)

### Lucy:
* Add option to `CalibratedClassifierCV` to have it implement calibration the same as in libsvm
(train on all output predictions instead of having ensemble of classifiers)
(finishing this PR https://github.com/scikit-learn/scikit-learn/pull/16167)
* PR on supporting pipelines in `CalibratedClassifierCV` to be merged before I can finish it: https://github.com/scikit-learn/scikit-learn/pull/17546 - review welcome
* Should I wait for the calibration loss PR to be merged before I finish the plot_calibration_curve PR (https://github.com/scikit-learn/scikit-learn/pull/17443) ?
* Also open to: ambitious contribution suggestions

### Olivier:
* Cloudpickle refactoring to make it possible to backport fast pickle5 to Python 3.6 and 3.7: https://github.com/cloudpipe/cloudpickle/pull/368
* Joblib + dask minor things to finish : https://github.com/joblib/joblib/pull/1055
* Follow-up on all issues raised at the monthly dev meeting + PRs from the sprint.

### Jérémie
* Link for minibatchkmeans I promised last time https://github.com/scikit-learn/scikit-learn/pull/17622
* Trying to understand T-sne algorithm to have good answer to https://github.com/scikit-learn/scikit-learn/issues/12401
* Looking for that “pick up an ambitious contribution to which you dedicate at least 50% of your time” :)

### Gaël
Working with Thomas on scikit-learn MOOC

### Alex
Working with Maria with deprecation of normalize parameter in linear models

### Suggestions for longer-term contribution:
* Missing values imputation with Matrix factorization (should be done with an online solver, as in MiniBatchDictLearning)
* K-means++ optimization (waiting for MiniBatchKmeans)
* Help on feature names PRs (maybe wait for the benchmark of Thomas?)
* Continue to extend prototype for NEP-37 / NEP-18 and give feed-back to numpy developers:
  * https://github.com/scikit-learn/scikit-learn/pull/17676
  * https://github.com/scikit-learn/scikit-learn/pull/17744
